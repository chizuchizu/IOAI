{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chizuchizu/IOAI/blob/main/Task2/chizu_000_task2_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dEDVuanhJGuV"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "\n",
        "class CFG:\n",
        "    num_workers=4\n",
        "    project = \"IOAI_Task2_classification\"\n",
        "    name = \"chizu_000_task2_complete\"\n",
        "\n",
        "    # pseudo_base_model_name = \"ioai2024japan/redrock_015_task2_finetune\"\n",
        "    base_model_name = \"google-bert/bert-base-multilingual-uncased\"\n",
        "    base_tokenizer_name = \"google-bert/bert-base-multilingual-uncased\"\n",
        "    # tokenizer_name = \"google-bert/bert-base-multilingual-uncased\"\n",
        "    num_classes = 5\n",
        "\n",
        "    # training\n",
        "    pretrain_epochs = 1\n",
        "    classification_epochs = 30\n",
        "    mlm_probability = 0.15\n",
        "\n",
        "    scheduler='linear' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
        "\n",
        "    lr = 1e-05\n",
        "\n",
        "    # dataset\n",
        "    max_length = 256\n",
        "\n",
        "    # T4: 32\n",
        "    # L4: 64\n",
        "    train_batch_size = 32\n",
        "    eval_batch_size = 32\n",
        "\n",
        "    seed=42\n",
        "    train=True\n",
        "\n",
        "    pseudo_size = 60000\n",
        "    pseudo_select_size = 1500\n",
        "\n",
        "    if_wandb = False\n",
        "\n",
        "# for wandb\n",
        "cfg = dict(vars(CFG))\n",
        "cfg = {k: v for k, v in cfg.items() if \"__\" not in k}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sV85hgL0yxn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e866aa7-b77b-4d3a-8fcb-f93241666389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masiatic-cheetah\u001b[0m (\u001b[33masiatic-cheetah-a\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "read_access_token = userdata.get('hf_read')\n",
        "write_access_token = userdata.get('hf_write')\n",
        "\n",
        "import importlib\n",
        "import torch, transformers\n",
        "\n",
        "if '2.3.0' not in torch.__version__:\n",
        "  !pip install torch==2.3.0\n",
        "if transformers.__version__!='4.41.2':\n",
        "  !pip install transformers==4.41.2\n",
        "\n",
        "if importlib.util.find_spec('datasets') is None:\n",
        "  !pip install datasets==2.18.0s\n",
        "  !pip install evaluate==0.4.2\n",
        "  !pip install accelerate -U\n",
        "\n",
        "if importlib.util.find_spec('wandb') is None:\n",
        "  !pip install wandb -q\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.functional import F\n",
        "import torch.cuda.amp as amp\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, get_scheduler, BertForMaskedLM, BertTokenizer\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
        "\n",
        "import evaluate\n",
        "\n",
        "import wandb\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "wandb.login(key=userdata.get('wandb_token'))\n",
        "login(token=read_access_token)\n",
        "\n",
        "brahmi_to_devanagari = {\n",
        "    '𑀓': 'क', '𑀔': 'ख', '𑀕': 'ग', '𑀖': 'घ', '𑀗': 'ङ', '𑀘': 'च', '𑀙': 'छ',\n",
        "    '𑀚': 'ज', '𑀛': 'झ', '𑀜': 'ञ', '𑀝': 'ट', '𑀞': 'ठ', '𑀟': 'ड', '𑀠': 'ढ',\n",
        "    '𑀡': 'ण', '𑀢': 'त', '𑀣': 'थ', '𑀤': 'द', '𑀥': 'ध', '𑀦': 'न', '𑀧': 'प',\n",
        "    '𑀨': 'फ', '𑀩': 'ब', '𑀪': 'भ', '𑀫': 'म', '𑀬': 'य', '𑀭': 'र', '𑀮': 'ल',\n",
        "    '𑀯': 'व', '𑀰': 'श', '𑀱': 'ष', '𑀲': 'स', '𑀳': 'ह', '𑁦':'०', '𑁣': '90'\n",
        "}\n",
        "\n",
        "def transliterate_brahmi_to_devanagari(text):\n",
        "    transliterated_text = ''\n",
        "    for char in text:\n",
        "        if char in brahmi_to_devanagari:\n",
        "            transliterated_text += brahmi_to_devanagari[char]\n",
        "        else:\n",
        "            transliterated_text += char\n",
        "    return transliterated_text\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return f1.compute(predictions=predictions, references=labels, average='macro')\n",
        "\n",
        "def to_device(batch, device):\n",
        "    output = {}\n",
        "    for k, v in batch.items():\n",
        "        try:\n",
        "            output[k] = v.to(device)\n",
        "        except:\n",
        "            output[k] = v\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_pseudo(model, train_loader, device):\n",
        "    model.eval()\n",
        "    predictions_list = []\n",
        "    confidences_list = []\n",
        "    for batch in tqdm(train_loader):\n",
        "        batch = to_device(batch, device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        confidences = F.softmax(logits, dim=-1)\n",
        "        pred_confidence,_ = confidences.max(dim=-1)\n",
        "        #pred_confidence,_ = pred_confidence_temp.max(dim=-1)\n",
        "        # print(pred_confidence.shape)\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        #predictions = torch.mode(predictions, dim=0).values\n",
        "        # print(predictions.shape)\n",
        "        predictions_list.extend(predictions.cpu().numpy())\n",
        "        confidences_list.extend(pred_confidence.cpu().numpy())\n",
        "\n",
        "    return predictions_list, confidences_list"
      ],
      "metadata": {
        "id": "S46cIsPy2ipO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pseudo_get_data(raw_dataset, transform_raw, finetuned_model_path, device):\n",
        "    pseudo_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        finetuned_model_path, num_labels=CFG.num_classes\n",
        "    ).cuda()\n",
        "\n",
        "    pseudo_size = CFG.pseudo_size\n",
        "\n",
        "    raw_eval_batch = raw_dataset[\"train\"].select(range(0, pseudo_size))\n",
        "\n",
        "    print(raw_eval_batch)\n",
        "\n",
        "    tokenized_eval_batch = raw_eval_batch.with_transform(transform_raw)\n",
        "\n",
        "    raw_loader = DataLoader(\n",
        "        tokenized_eval_batch,\n",
        "        batch_size=CFG.train_batch_size,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    predictions, confidences = pred_pseudo(model, raw_loader, device)\n",
        "\n",
        "    top_conf = np.argsort(confidences)[-CFG.pseudo_select_size:]\n",
        "\n",
        "    selected_texts = [transliterate_brahmi_to_devanagari(raw_eval_batch[int(i)][\"text\"]) for i in top_conf]\n",
        "    selected_labels = [predictions[int(i)] for i in top_conf]\n",
        "\n",
        "    pseudo_labeled_dataset = Dataset.from_dict({\n",
        "        'text': selected_texts,\n",
        "        'label': selected_labels\n",
        "    })\n",
        "\n",
        "    return pseudo_labeled_dataset, confidences"
      ],
      "metadata": {
        "id": "9PcOj9AF2oHJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tokenizer(raw_dataset):\n",
        "    train_corpus = []\n",
        "\n",
        "    num_cores = 8\n",
        "\n",
        "    train_corpus = Parallel(n_jobs=num_cores)(\n",
        "        delayed(transliterate_brahmi_to_devanagari)(text) for text in tqdm(raw_dataset['train'][\"text\"])\n",
        "    )\n",
        "\n",
        "    # print(train_corpus[:5])\n",
        "\n",
        "    old_tokenizer = AutoTokenizer.from_pretrained(CFG.base_tokenizer_name)\n",
        "\n",
        "    tokenizer = old_tokenizer.train_new_from_iterator(train_corpus, old_tokenizer.vocab_size)\n",
        "\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "MDkb_0oWkPcn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, scheduler, train_loader, optimizer, fp16=True):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(train_loader, dynamic_ncols=True)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for step, batch in enumerate(progress_bar):\n",
        "        batch = to_device(batch, \"cuda\")\n",
        "\n",
        "        if fp16:\n",
        "            with amp.autocast():\n",
        "                outputs = model(\n",
        "                    input_ids=batch[\"input_ids\"],\n",
        "                    attention_mask=batch[\"attention_mask\"],\n",
        "                    token_type_ids=batch[\"token_type_ids\"],\n",
        "                    labels=batch[\"labels\"],\n",
        "                )\n",
        "                loss = outputs.loss\n",
        "\n",
        "            # Scale loss for fp16 training\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Optimizer step with gradient scaling\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "        else:\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                token_type_ids=batch[\"token_type_ids\"],\n",
        "                labels=batch[\"labels\"],\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        text = f\"step {step}, loss: {loss:.5f}\"\n",
        "        progress_bar.set_description(text)\n",
        "\n",
        "def evaluate_model(model, eval_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    for batch in eval_loader:\n",
        "        batch = to_device(batch, \"cuda\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                token_type_ids=batch[\"token_type_ids\"],\n",
        "                labels=batch[\"labels\"],\n",
        "            )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=-1)\n",
        "        predictions.append(prediction.cpu().numpy())\n",
        "        labels.append(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "    predictions = np.concatenate(predictions)\n",
        "    labels = np.concatenate(labels)\n",
        "    return f1.compute(predictions=predictions, references=labels, average='macro')"
      ],
      "metadata": {
        "id": "WLX-zdDfdTXy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain(raw_dataset, tokenizer, transform_raw):\n",
        "    print(\"=== Pretrain ===\")\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=True,\n",
        "        mlm_probability=CFG.mlm_probability\n",
        "    )\n",
        "\n",
        "    tokenized_data = raw_dataset.with_transform(transform_raw)\n",
        "\n",
        "    train_dataset = tokenized_data[\"train\"]\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CFG.train_batch_size,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    model = BertForMaskedLM.from_pretrained(\n",
        "        CFG.base_model_name\n",
        "    ).cuda()\n",
        "\n",
        "    num_training_steps = CFG.pretrain_epochs * len(train_loader)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=CFG.lr)\n",
        "    scheduler = get_scheduler(name=CFG.scheduler, optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "    for i in range(CFG.pretrain_epochs):\n",
        "        train_one_epoch(model, scheduler, train_loader, optimizer)\n",
        "        print(f'Epoch {i+1}')\n",
        "\n",
        "    model_path = f\"{CFG.name}_pretrain\"\n",
        "    model.save_pretrained(model_path)\n",
        "    return model_path"
      ],
      "metadata": {
        "id": "1SSBvno3jCGv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetine(base_model, train_dataset, eval_dataset, device):\n",
        "    print(\"=== Finetune ===\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        base_model, num_labels=CFG.num_classes\n",
        "    ).cuda()\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CFG.train_batch_size,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    eval_loader = DataLoader(\n",
        "        eval_dataset,\n",
        "        batch_size=CFG.eval_batch_size,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    num_training_steps = CFG.classification_epochs * len(train_loader)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=CFG.lr)\n",
        "    scheduler = get_scheduler(name=CFG.scheduler, optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "    model.to(device)\n",
        "    for i in range(CFG.classification_epochs):\n",
        "        train_one_epoch(model, scheduler, train_loader, optimizer)\n",
        "        accuracy = evaluate_model(model, eval_loader)\n",
        "        print(f'Epoch {i+1} {accuracy}')\n",
        "\n",
        "    model_path = f\"{CFG.name}_finetune\"\n",
        "    model.save_pretrained(model_path)\n",
        "    return model_path"
      ],
      "metadata": {
        "id": "jXAjWlZFmBlm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cHRDuKNBj5IW"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    if CFG.if_wandb:\n",
        "        wandb.init(\n",
        "            name=CFG.name,\n",
        "            project=CFG.project,\n",
        "            config=cfg\n",
        "        )\n",
        "\n",
        "    raw_dataset = load_dataset('InternationalOlympiadAI/NLP_problem_raw', token=read_access_token)\n",
        "    classification_dataset = load_dataset('InternationalOlympiadAI/NLP_problem', token=read_access_token)\n",
        "\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    # Train tokenizer to Lang X\n",
        "    tokenizer = train_tokenizer(raw_dataset)\n",
        "\n",
        "    # for raw set\n",
        "    def transform_raw(example_batch):\n",
        "        example_batch[\"text\"] = [transliterate_brahmi_to_devanagari(x) for x in example_batch[\"text\"]]\n",
        "        inputs = tokenizer([x for x in example_batch[\"text\"]],  truncation=True, max_length=CFG.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        return inputs\n",
        "\n",
        "    # for problem set\n",
        "    def transform(example_batch):\n",
        "        example_batch[\"text\"] = [transliterate_brahmi_to_devanagari(x) for x in example_batch[\"text\"]]\n",
        "        inputs = tokenizer([x for x in example_batch[\"text\"]],  truncation=True, max_length=CFG.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        inputs[\"labels\"] = example_batch[\"label\"]\n",
        "        return inputs\n",
        "\n",
        "    tokenized_data = classification_dataset.with_transform(transform)\n",
        "\n",
        "    train_dataset = tokenized_data[\"train\"]\n",
        "    eval_dataset = tokenized_data[\"dev\"]\n",
        "\n",
        "    # Continual Pre-Training of MLM\n",
        "    pretrained_model_path = pretrain(raw_dataset, tokenizer, transform_raw)\n",
        "    # Finetune with normal dataset\n",
        "    finetuned_model_path = finetine(pretrained_model_path, train_dataset, eval_dataset, device)\n",
        "\n",
        "    # Get pseudo label\n",
        "    pseudo_data, confidences = pseudo_get_data(raw_dataset, transform_raw, finetuned_model_path, device)\n",
        "    pseudo_labeled_tokens = pseudo_data.with_transform(transform)\n",
        "\n",
        "    combined_train_dataset = concatenate_datasets([pseudo_labeled_tokens, train_dataset])\n",
        "\n",
        "    # Finetune with pseudo dataset and normal dataset\n",
        "    final_model_name = finetine(pretrained_model_path, combined_train_dataset, eval_dataset, device)\n",
        "\n",
        "    return final_model_name, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs02eqO9jQBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "0a654e736204435db1c432723ee003d7",
            "a3353e2bb98447328c91c4ae965a3de6",
            "b2668c922b13413e964d8882e330167c",
            "1e52e1f3e226465b8092b6efe1ae7ccd",
            "670f54c044dc4515916b6480e0a4d897",
            "d8a2de88d40d4ca3aaf7a4d75bd2e4db",
            "0093f5314e9e421aa3a0d0d883852e60",
            "93c3a30595c54814a99b1f1441cb037d",
            "85562dfd3a144f85bc302559d4d021ee",
            "6355fa2a8d7c42e0a6301fa9186861ba",
            "b1186454cdf04ab5a5dad21290fe06b2",
            "9e00f31f331d4275b63fe7ba5f2d669c",
            "956084a196384ef7b28c7a9d3edab527",
            "09a64ce1b5f344cf82a8df866da452d9",
            "26da175d83af4691a0cbd275b7807ddb",
            "598af85b2a2a48628876c8015f54c08d",
            "75bfeb05976c432abe55701aba049ac5",
            "4688e07eac184f7b861287e2318226a5",
            "73b2a2ce1d8044a68db99ec26ade8b3f",
            "e9085dbc19fc442297fd0856cd1bb2da",
            "5bddd9012ba94f509731df95ba9c595e",
            "ff3d9d3a96214d1a8740c2fb79d1c283"
          ]
        },
        "outputId": "c69bcc00-a24d-45a9-ed43-23735f87bc7c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/611245 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a654e736204435db1c432723ee003d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Pretrain ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/19101 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e00f31f331d4275b63fe7ba5f2d669c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "final_model_name, tokeniezr = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMNqHsF0olYA"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    final_model_name, num_labels=CFG.num_classes\n",
        ")\n",
        "model.push_to_hub(\n",
        "    f\"ioai2024japan/{CFG.name}\",\n",
        "    token=userdata.get('hf_write'), private=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\n",
        "    f\"ioai2024japan/{CFG.name}\",\n",
        "    token=userdata.get('hf_write'), private=True\n",
        ")"
      ],
      "metadata": {
        "id": "hXu9isI7tsZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a654e736204435db1c432723ee003d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3353e2bb98447328c91c4ae965a3de6",
              "IPY_MODEL_b2668c922b13413e964d8882e330167c",
              "IPY_MODEL_1e52e1f3e226465b8092b6efe1ae7ccd"
            ],
            "layout": "IPY_MODEL_670f54c044dc4515916b6480e0a4d897"
          }
        },
        "a3353e2bb98447328c91c4ae965a3de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a2de88d40d4ca3aaf7a4d75bd2e4db",
            "placeholder": "​",
            "style": "IPY_MODEL_0093f5314e9e421aa3a0d0d883852e60",
            "value": "100%"
          }
        },
        "b2668c922b13413e964d8882e330167c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c3a30595c54814a99b1f1441cb037d",
            "max": 611245,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85562dfd3a144f85bc302559d4d021ee",
            "value": 611245
          }
        },
        "1e52e1f3e226465b8092b6efe1ae7ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6355fa2a8d7c42e0a6301fa9186861ba",
            "placeholder": "​",
            "style": "IPY_MODEL_b1186454cdf04ab5a5dad21290fe06b2",
            "value": " 611245/611245 [00:06&lt;00:00, 112229.01it/s]"
          }
        },
        "670f54c044dc4515916b6480e0a4d897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a2de88d40d4ca3aaf7a4d75bd2e4db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0093f5314e9e421aa3a0d0d883852e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c3a30595c54814a99b1f1441cb037d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85562dfd3a144f85bc302559d4d021ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6355fa2a8d7c42e0a6301fa9186861ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1186454cdf04ab5a5dad21290fe06b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e00f31f331d4275b63fe7ba5f2d669c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_956084a196384ef7b28c7a9d3edab527",
              "IPY_MODEL_09a64ce1b5f344cf82a8df866da452d9",
              "IPY_MODEL_26da175d83af4691a0cbd275b7807ddb"
            ],
            "layout": "IPY_MODEL_598af85b2a2a48628876c8015f54c08d"
          }
        },
        "956084a196384ef7b28c7a9d3edab527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75bfeb05976c432abe55701aba049ac5",
            "placeholder": "​",
            "style": "IPY_MODEL_4688e07eac184f7b861287e2318226a5",
            "value": "step 502, loss: 7.46712:   3%"
          }
        },
        "09a64ce1b5f344cf82a8df866da452d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b2a2ce1d8044a68db99ec26ade8b3f",
            "max": 19101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9085dbc19fc442297fd0856cd1bb2da",
            "value": 503
          }
        },
        "26da175d83af4691a0cbd275b7807ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bddd9012ba94f509731df95ba9c595e",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3d9d3a96214d1a8740c2fb79d1c283",
            "value": " 503/19101 [04:18&lt;2:38:35,  1.95it/s]"
          }
        },
        "598af85b2a2a48628876c8015f54c08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "75bfeb05976c432abe55701aba049ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4688e07eac184f7b861287e2318226a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73b2a2ce1d8044a68db99ec26ade8b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9085dbc19fc442297fd0856cd1bb2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bddd9012ba94f509731df95ba9c595e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3d9d3a96214d1a8740c2fb79d1c283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}