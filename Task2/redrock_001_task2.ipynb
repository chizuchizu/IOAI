{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23c4aae80af4473a8e2ac0d8fe574ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7bf173e78a440b582dfe67b908a96d1",
              "IPY_MODEL_16ad7c1f074241788fd468e1c8352597",
              "IPY_MODEL_f84a174c981d46dfb30ee60546aff247"
            ],
            "layout": "IPY_MODEL_b7dd71cbe9c24c0a8990d7a2af865ad2"
          }
        },
        "b7bf173e78a440b582dfe67b908a96d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63519333c0824cb6880a90e61cd310dd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f9516226370244068d7409083be38c06",
            "value": "Map:‚Äá100%"
          }
        },
        "16ad7c1f074241788fd468e1c8352597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210e1c8e797c4753bd6ea68c970b961b",
            "max": 218,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47ac6f5755954e7fa5c4cb7ad97d9428",
            "value": 218
          }
        },
        "f84a174c981d46dfb30ee60546aff247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0c599d84c64e55a0bc011d72be99e4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9568236dee78489d8a8d507a2a783fb8",
            "value": "‚Äá218/218‚Äá[00:00&lt;00:00,‚Äá4186.78‚Äáexamples/s]"
          }
        },
        "b7dd71cbe9c24c0a8990d7a2af865ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63519333c0824cb6880a90e61cd310dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9516226370244068d7409083be38c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "210e1c8e797c4753bd6ea68c970b961b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ac6f5755954e7fa5c4cb7ad97d9428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df0c599d84c64e55a0bc011d72be99e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9568236dee78489d8a8d507a2a783fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chizuchizu/IOAI/blob/main/Task2/redrock_001_task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Help BOBAI: Classify an unknown language"
      ],
      "metadata": {
        "id": "bqAFpqJlnt77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1Hvgrrah-T7yFTzDP002XuRodhyfY1Hju\" width=\"750\">\n",
        "\n",
        "## Background\n",
        "Bob's AI start-up, Bobai, builds AI solutions for other companies which have to process large volumes of text in their daily tasks. Bobai serve companies from all over the world, and they pride themselves on their ability to handle a variety of languages, from English, through Arabic to Mandarin. The secret to Bobai's success is that all of their products are based on a strong multilingual language encoder, mBERT. Bobai's infrastructure is actually highly optimized for this specific language encoder, which makes their products super fast and efficient, i.e. very attractive to clients.\n",
        "\n",
        "## Task\n",
        "\n",
        "But mBERT is trained on just 101 languages. So what happens when one of Bobai's biggest clients, Amoira, requests support for a new language X that is not among those 101 languages? Bob and his team have to find a way to meet this request, as they cannot risk losing the client.\n",
        "\n",
        "The data Amoira has provided consists of a small labeled dataset for text classification and a larger corpus or raw text in the language.\n",
        "\n",
        "To make things even more complicated, Amoira has encrypted the data, as they don't want to risk competitors finding out which new market they are targetting.\n",
        "\n",
        "Bob has found out that at this time his team has no bandwidth to develop this product, so he is asking for your help. He has shared the baseline solution he uses for languages that mBERT already has support for, so you can start by checking how well this solution does and modify it to obtain better results. You should not waste any efforts on trying to decrypt the data - this will not help you build a better classifier and it will get you in trouble with Bob!\n",
        "\n",
        "Your task is to build the best text classifier for language X that you can, while operating within the constraints of Bobai:\n",
        "\n",
        "*   The classifier has to be based on mBERT (and cannot use any additional pre-trained language encoder).\n",
        "*   The classifier has to train in under 8 hours using an L4 GPU as the compute resources of the company are limited.\n",
        "*   The classifier has to perform inference on any random 500 data samples in under 5 minutes (Bobai will then apply their optimization tricks to bring this time even further down).\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "You need to submit:\n",
        "\n",
        "\n",
        "*   Your model predictions on the test inputs that we will provide 48 hours before the deadline.\n",
        "  * saved as a text file in the format shown at the bottom of the notebook\n",
        "*   Your best trained model.\n",
        "  * as a link to the Huggingface Hub (read up on `push_to_hub` [here](push_to_hub)).\n",
        "*   Working code that can be used to reproduce your best trained model.\n",
        "  * In this Colab notebook.\n"
      ],
      "metadata": {
        "id": "vu6E-5QWIjlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n"
      ],
      "metadata": {
        "id": "J6BNTewtA-Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HuggingFace configuration\n",
        "\n",
        "The steps below need to be completed by the team leader:\n",
        "\n",
        "1. Create a team account on [HuggingFace](https://huggingface.co/) using the Gmail account provided by the IOAI organizers.\n",
        "\n",
        "2. Go to the [IOAI HuggingFace repo](https://huggingface.co/InternationalOlympiadAI) and request access to all datasets.\n",
        "\n",
        "3. In settings, create two Access Tokens, one with read rights, one with write rights, and store those in [Colab Secrets](https://www.youtube.com/watch?v=q87i2LZbbPc) as `hf_read` and `hf_write`, respectively."
      ],
      "metadata": {
        "id": "0Tg2sPb2ELb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "read_access_token = userdata.get('hf_read')\n",
        "write_access_token = userdata.get('hf_write')"
      ],
      "metadata": {
        "id": "sV85hgL0yxn0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "SyLH6A-YEJG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import torch, transformers\n",
        "\n",
        "if '2.3.0' not in torch.__version__:\n",
        "  !pip install torch==2.3.0\n",
        "if transformers.__version__!='4.41.2':\n",
        "  !pip install transformers==4.41.2\n",
        "\n",
        "if importlib.util.find_spec('datasets') is None:\n",
        "  !pip install datasets==2.18.0s\n",
        "  !pip install evaluate==0.4.2\n",
        "  !pip install accelerate -U\n"
      ],
      "metadata": {
        "id": "8VH0WJYuM_4Z",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you've just installed `accelerate`, execute `Runtime > Restart session and run all` in the Colab UI menu above."
      ],
      "metadata": {
        "id": "zridt_PWpd9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "EFTIQ9tDMqsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "classification_dataset = load_dataset('InternationalOlympiadAI/NLP_problem', token=read_access_token)\n",
        "raw_text = load_dataset('InternationalOlympiadAI/NLP_problem_raw', token=read_access_token)"
      ],
      "metadata": {
        "id": "CpgcmI2NMLyF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "cv9MBElmMs6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pre-trained tokenizer and use it to process the data\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")\n",
        "\n",
        "brahmi_to_devanagari = {\n",
        "    'ëÄì': '‡§ï', 'ëÄî': '‡§ñ', 'ëÄï': '‡§ó', 'ëÄñ': '‡§ò', 'ëÄó': '‡§ô', 'ëÄò': '‡§ö', 'ëÄô': '‡§õ',\n",
        "    'ëÄö': '‡§ú', 'ëÄõ': '‡§ù', 'ëÄú': '‡§û', 'ëÄù': '‡§ü', 'ëÄû': '‡§†', 'ëÄü': '‡§°', 'ëÄ†': '‡§¢',\n",
        "    'ëÄ°': '‡§£', 'ëÄ¢': '‡§§', 'ëÄ£': '‡§•', 'ëÄ§': '‡§¶', 'ëÄ•': '‡§ß', 'ëÄ¶': '‡§®', 'ëÄß': '‡§™',\n",
        "    'ëÄ®': '‡§´', 'ëÄ©': '‡§¨', 'ëÄ™': '‡§≠', 'ëÄ´': '‡§Æ', 'ëÄ¨': '‡§Ø', 'ëÄ≠': '‡§∞', 'ëÄÆ': '‡§≤',\n",
        "    'ëÄØ': '‡§µ', 'ëÄ∞': '‡§∂', 'ëÄ±': '‡§∑', 'ëÄ≤': '‡§∏', 'ëÄ≥': '‡§π', 'ëÅ¶':'‡•¶', 'ëÅ£': '90'\n",
        "}\n",
        "\n",
        "def transliterate_brahmi_to_devanagari(text):\n",
        "    transliterated_text = ''\n",
        "    for char in text:\n",
        "        if char in brahmi_to_devanagari:\n",
        "            transliterated_text += brahmi_to_devanagari[char]\n",
        "        else:\n",
        "            transliterated_text += char\n",
        "    return transliterated_text\n",
        "\n",
        "transliteration_dict = {\n",
        "    '‡§ï': 'k', '‡§ñ': 'kh', '‡§ó': 'ga', '‡§ò': 'gh', '‡§ô': 'ng',\n",
        "    '‡§ö': 'k', '‡§õ': 'ch', '‡§ú': 'j', '‡§ù': 'jh', '‡§û': 'ny',\n",
        "    '‡§ü': 't', '‡§†': 'th', '‡§°': 'd', '‡§¢': 'dh', '‡§£': 'n',\n",
        "    '‡§§': 't', '‡§•': 'th', '‡§¶': 'd', '‡§ß': 'dh', '‡§®': 'n',\n",
        "    '‡§™': 'p', '‡§´': 'f', '‡§¨': 'b', '‡§≠': 'bh', '‡§Æ': 'm',\n",
        "    '‡§Ø': 'y', '‡§∞': 'r', '‡§≤': 'l', '‡§µ': 'v', '‡§∂': 'sh',\n",
        "    '‡§∑': 's', '‡§∏': 's', '‡§π': 'h', '‡•ò': 'k', '‡•ô': 'kh',\n",
        "    '‡•ö': 'g', '‡§©': 'n', '‡•ú': 'd', '‡§¢': 'dh', '‡•ù': 'rh',\n",
        "    '‡§±': 'r', '‡•ü': 'ye', '‡§≥': 'l', '‡§¥': 'll', '‡•û': 'f',\n",
        "    '‡•õ': 'z', '‡§ã': 'ri', '‡§æ': 'aa', '‡§ø': 'i', '‡•Ä': 'i',\n",
        "    '‡•Å': 'u', '‡•Ç': 'u', '‡•Ö': 'e', '‡•Ü': 'e', '‡•á': 'e',\n",
        "    '‡•à': 'ai', '‡•â': 'o', '‡•ä': 'o', '‡•ã': 'o', '‡•å': 'au',\n",
        "    '‡§Ö': 'a', '‡§Ü': 'aa', '‡§á': 'i', '‡§à': 'i', '‡§â': 'u',\n",
        "    '‡§ä': 'oo', '‡§è': 'e', '‡§ê': 'ai', '‡§ë': 'au', '‡§ì': 'o',\n",
        "    '‡§î': 'au', '‡§Å': 'n', '‡§Ç': 'n', '‡§É': 'ah', '‡§º': 'e',\n",
        "    '‡•ç': '', '‡•¶': '0', '‡•ß': '1', '‡•®': '2', '‡•©': '3',\n",
        "    '‡•™': '4', '‡•´': '5', '‡•¨': '6', '‡•≠': '7', '‡•Æ': '8',\n",
        "    '‡•Ø': '9', '‡•§': '.', '‡§ç': 'e', '‡•É': 'ri', '‡•Ñ': 'rr',\n",
        "    '‡•†': 'r', '‡§å': 'l', '‡•£': 'l', '‡•¢': 'l', '‡•°': 'l',\n",
        "    '‡•ø': 'b', '‡•æ': 'd', '‡•Ω': '', '‡•º': 'j', '‡•ª': 'g',\n",
        "    '‡•ê': 'om', '‡§Ω': \"'\", 'e.a': 'a', '\\n': '\\n'\n",
        "}\n",
        "\n",
        "def transliterate_text(text):\n",
        "    for key, value in transliteration_dict.items():\n",
        "        text = text.replace(key, value)\n",
        "    return text\n",
        "\n",
        "def transliterate_brahmi_to_latin(text):\n",
        "    transliterated_text = ''\n",
        "    for char in text:\n",
        "        if char in brahmi_to_devanagari:\n",
        "            transliterated_text += brahmi_to_devanagari[char]\n",
        "        else:\n",
        "            transliterated_text += char\n",
        "    return transliterated_text\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    examples[\"text\"] = [transliterate_brahmi_to_latin(text) for text in examples[\"text\"]]\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_data = classification_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "tSOWNJRKNoWM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "23c4aae80af4473a8e2ac0d8fe574ed1",
            "b7bf173e78a440b582dfe67b908a96d1",
            "16ad7c1f074241788fd468e1c8352597",
            "f84a174c981d46dfb30ee60546aff247",
            "b7dd71cbe9c24c0a8990d7a2af865ad2",
            "63519333c0824cb6880a90e61cd310dd",
            "f9516226370244068d7409083be38c06",
            "210e1c8e797c4753bd6ea68c970b961b",
            "47ac6f5755954e7fa5c4cb7ad97d9428",
            "df0c599d84c64e55a0bc011d72be99e4",
            "9568236dee78489d8a8d507a2a783fb8"
          ]
        },
        "outputId": "053b7af8-d582-4b3b-f065-635f531746ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/218 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23c4aae80af4473a8e2ac0d8fe574ed1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the evaluation metric\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return f1.compute(predictions=predictions, references=labels, average='macro')"
      ],
      "metadata": {
        "id": "nN64VrhSNuYA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp6oUqPq-0vT",
        "outputId": "af8ed327-545f-498a-c439-b681fb46adc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.32.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model and the training configuration\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google-bert/bert-base-multilingual-uncased\", num_labels=5\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"basiline_bobai\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=20,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=5,\n",
        "    metric_for_best_model='f1',\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    hub_strategy=\"checkpoint\",\n",
        "    hub_token=write_access_token,\n",
        "    hub_private_repo=True,\n",
        "    hub_model_id='baseline_bobai'\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"dev\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "hCojWe8hOgRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebdffa2-a6da-4b8d-f0fa-74c125c05b7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# execute the model training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "VTJ-w6BnosYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "76e18b67-5312-4c68-c42b-abca0fb2a49e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 02:23, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.600234</td>\n",
              "      <td>0.156712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.568969</td>\n",
              "      <td>0.181892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.548950</td>\n",
              "      <td>0.188739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.521567</td>\n",
              "      <td>0.184506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.481484</td>\n",
              "      <td>0.231446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.474720</td>\n",
              "      <td>0.248667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.453247</td>\n",
              "      <td>0.321109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.444793</td>\n",
              "      <td>0.270465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.427314</td>\n",
              "      <td>0.286884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.400559</td>\n",
              "      <td>0.372912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.368273</td>\n",
              "      <td>0.362427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.418138</td>\n",
              "      <td>0.251449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.356027</td>\n",
              "      <td>0.346873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.327694</td>\n",
              "      <td>0.351768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.308995</td>\n",
              "      <td>0.380444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.314051</td>\n",
              "      <td>0.337912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.327930</td>\n",
              "      <td>0.331565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.312453</td>\n",
              "      <td>0.324854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.294886</td>\n",
              "      <td>0.323051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.291465</td>\n",
              "      <td>0.336245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=80, training_loss=1.4687346458435058, metrics={'train_runtime': 145.5979, 'train_samples_per_second': 29.945, 'train_steps_per_second': 0.549, 'total_flos': 179968698224400.0, 'train_loss': 1.4687346458435058, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "oSYydzx9NAGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run the trained model on a dev/test split\n",
        "data_split = \"dev\"\n",
        "eval_out = trainer.predict(tokenized_data[data_split])\n",
        "predictions = eval_out.predictions.argmax(1)\n",
        "labels = eval_out.label_ids\n",
        "dev_f1 = f1.compute(predictions=predictions, references=labels, average='macro')"
      ],
      "metadata": {
        "id": "jaa80VhiNBG_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4a8c50d2-99c5-451f-b444-e6c6bb356379"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFUe7vaSAHl3",
        "outputId": "f29f996d-297e-4de7-c596-7c41ece8a5d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.3804444818284412}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write the predictions to a file\n",
        "with open('{}_predictions.txt'.format(data_split), 'w') as outfile:\n",
        "  outfile.write('\\n'.join([str(p) for p in predictions.tolist()]))"
      ],
      "metadata": {
        "id": "ERSnemwvKz5v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transliterate"
      ],
      "metadata": {
        "id": "iGD9HT_m0g97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#„Éá„Éº„Çø„Åã„ÇâÊñáÂ≠óÂàó„Å†„Åë„ÇíÂèñ„Çã\n",
        "\n",
        "train_data_len = len(tokenized_data[\"train\"])\n",
        "train_data_texts = []\n",
        "for i in range(train_data_len):\n",
        "    train_single_text = tokenized_data[\"train\"][i][\"text\"]\n",
        "    train_data_texts.append(train_single_text)\n",
        "\n",
        "print(train_data_texts[0])\n",
        "\n",
        "dev_data_len = len(tokenized_data[\"dev\"])\n",
        "dev_data_texts = []\n",
        "for i in range(dev_data_len):\n",
        "    dev_single_text = tokenized_data[\"dev\"][i][\"text\"]\n",
        "    dev_data_texts.append(dev_single_text)\n",
        "\n",
        "print(dev_data_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AmzkjZ71-Mi",
        "outputId": "edffa89d-cb09-4771-a62a-a5dfe430afc2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡§¢‡§ö‡§¨‡§®‡§§‡§≠‡•¶ ‡§•‡§ö ‡§ñ‡§ö‡§≠‡§ö‡§°‡•¶ ‡§¢‡§ö ‡§¶‡§ö ‡§π‡§® ‡§¢‡§®‡§¨‡§ö ‡§∑‡§ö‡§π‡§ö‡§° ‡§¢‡§ö‡§° ‡§® ‡§¢‡§ö\n",
            "‡§¢‡§ö‡§¨‡§®‡§§‡§≠‡•¶ ‡§•‡§ö ‡§ñ‡§ö‡§≠‡§ö‡§°‡•¶ ‡§¢‡§ö ‡§¶‡§ö ‡§π‡§® ‡§¢‡§®‡§¨‡§ö ‡§∑‡§ö‡§π‡§ö‡§° ‡§¢‡§ö‡§° ‡§® ‡§¢‡§ö\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brahmi_to_devanagari = {\n",
        "    'ëÄì': '‡§ï', 'ëÄî': '‡§ñ', 'ëÄï': '‡§ó', 'ëÄñ': '‡§ò', 'ëÄó': '‡§ô', 'ëÄò': '‡§ö', 'ëÄô': '‡§õ',\n",
        "    'ëÄö': '‡§ú', 'ëÄõ': '‡§ù', 'ëÄú': '‡§û', 'ëÄù': '‡§ü', 'ëÄû': '‡§†', 'ëÄü': '‡§°', 'ëÄ†': '‡§¢',\n",
        "    'ëÄ°': '‡§£', 'ëÄ¢': '‡§§', 'ëÄ£': '‡§•', 'ëÄ§': '‡§¶', 'ëÄ•': '‡§ß', 'ëÄ¶': '‡§®', 'ëÄß': '‡§™',\n",
        "    'ëÄ®': '‡§´', 'ëÄ©': '‡§¨', 'ëÄ™': '‡§≠', 'ëÄ´': '‡§Æ', 'ëÄ¨': '‡§Ø', 'ëÄ≠': '‡§∞', 'ëÄÆ': '‡§≤',\n",
        "    'ëÄØ': '‡§µ', 'ëÄ∞': '‡§∂', 'ëÄ±': '‡§∑', 'ëÄ≤': '‡§∏', 'ëÄ≥': '‡§π', 'ëÅ¶':'‡•¶', 'ëÅ£': '90'\n",
        "}\n",
        "\n",
        "def transliterate_brahmi_to_latin(text):\n",
        "    transliterated_text = ''\n",
        "    for char in text:\n",
        "        if char in brahmi_to_devanagari:\n",
        "            transliterated_text += brahmi_to_devanagari[char]\n",
        "        else:\n",
        "            transliterated_text += char\n",
        "    return transliterated_text\n",
        "\n",
        "transliteration_dict = {\n",
        "    '‡§ï': 'k', '‡§ñ': 'kh', '‡§ó': 'ga', '‡§ò': 'gh', '‡§ô': 'ng',\n",
        "    '‡§ö': 'k', '‡§õ': 'ch', '‡§ú': 'j', '‡§ù': 'jh', '‡§û': 'ny',\n",
        "    '‡§ü': 't', '‡§†': 'th', '‡§°': 'd', '‡§¢': 'dh', '‡§£': 'n',\n",
        "    '‡§§': 't', '‡§•': 'th', '‡§¶': 'd', '‡§ß': 'dh', '‡§®': 'n',\n",
        "    '‡§™': 'p', '‡§´': 'f', '‡§¨': 'b', '‡§≠': 'bh', '‡§Æ': 'm',\n",
        "    '‡§Ø': 'y', '‡§∞': 'r', '‡§≤': 'l', '‡§µ': 'v', '‡§∂': 'sh',\n",
        "    '‡§∑': 's', '‡§∏': 's', '‡§π': 'h', '‡•ò': 'k', '‡•ô': 'kh',\n",
        "    '‡•ö': 'g', '‡§©': 'n', '‡•ú': 'd', '‡§¢': 'dh', '‡•ù': 'rh',\n",
        "    '‡§±': 'r', '‡•ü': 'ye', '‡§≥': 'l', '‡§¥': 'll', '‡•û': 'f',\n",
        "    '‡•õ': 'z', '‡§ã': 'ri', '‡§æ': 'aa', '‡§ø': 'i', '‡•Ä': 'i',\n",
        "    '‡•Å': 'u', '‡•Ç': 'u', '‡•Ö': 'e', '‡•Ü': 'e', '‡•á': 'e',\n",
        "    '‡•à': 'ai', '‡•â': 'o', '‡•ä': 'o', '‡•ã': 'o', '‡•å': 'au',\n",
        "    '‡§Ö': 'a', '‡§Ü': 'aa', '‡§á': 'i', '‡§à': 'i', '‡§â': 'u',\n",
        "    '‡§ä': 'oo', '‡§è': 'e', '‡§ê': 'ai', '‡§ë': 'au', '‡§ì': 'o',\n",
        "    '‡§î': 'au', '‡§Å': 'n', '‡§Ç': 'n', '‡§É': 'ah', '‡§º': 'e',\n",
        "    '‡•ç': '', '‡•¶': '0', '‡•ß': '1', '‡•®': '2', '‡•©': '3',\n",
        "    '‡•™': '4', '‡•´': '5', '‡•¨': '6', '‡•≠': '7', '‡•Æ': '8',\n",
        "    '‡•Ø': '9', '‡•§': '.', '‡§ç': 'e', '‡•É': 'ri', '‡•Ñ': 'rr',\n",
        "    '‡•†': 'r', '‡§å': 'l', '‡•£': 'l', '‡•¢': 'l', '‡•°': 'l',\n",
        "    '‡•ø': 'b', '‡•æ': 'd', '‡•Ω': '', '‡•º': 'j', '‡•ª': 'g',\n",
        "    '‡•ê': 'om', '‡§Ω': \"'\", 'e.a': 'a', '\\n': '\\n'\n",
        "}\n",
        "\n",
        "def transliterate_text(text):\n",
        "    for key, value in transliteration_dict.items():\n",
        "        text = text.replace(key, value)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "8FyJLfu28cjn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transliterate_train_data = []\n",
        "# print(len(train_data_texts))\n",
        "for brahmi in train_data_texts:\n",
        "    devanagari = transliterate_brahmi_to_latin(brahmi)\n",
        "    latin = transliterate_text(devanagari)\n",
        "    transliterate_train_data.append(latin)\n",
        "\n",
        "print(transliterate_train_data[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsdoIwu-8gje",
        "outputId": "3dd40c7c-97f1-4bb1-9bff-92eed397cdfd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "klsdkhhbh pk hknthtnnk dk dkskbhttd bh90dklth90n dhkn0bhd dhndttm dk h90d bhtt0\n"
          ]
        }
      ]
    }
  ]
}