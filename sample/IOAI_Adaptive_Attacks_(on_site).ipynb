{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Can **you** break computer vision model?\n",
        "## On-site round"
      ],
      "metadata": {
        "id": "F5Exz32-J_-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Break a network by hand\n",
        "\n"
      ],
      "metadata": {
        "id": "DNIfM-c5akQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose you have a neural network $M$, defined b $M(x) = \\text{softmax}\\left(x^\\top\\theta\\right)$. Note that for $z\\in\\mathbb{R}^n$ we have $\\text{softmax}(z)=\\frac{1}{\\sum_i \\exp(z_i)}\\cdot\\left[\\exp(z_1), \\exp(z_2), \\ldots, \\exp(z_n)\\right]$.\n",
        "\n",
        "Further, let $x=[1.,2.,3.]$ be an input of interest and let $\\theta=\\begin{bmatrix}\n",
        "    5. & -2. \\\\\n",
        "    3. & 4. \\\\\n",
        "    2. & -1.\n",
        "\\end{bmatrix}$. Compute an an adversarial example $x^\\prime$ that maximizes the second coordinate of $M(x)$ under the constraint that $\\|x^\\prime-x\\|_\\infty \\leq 1.$, i.e., you're creating an $\\ell_\\infty$ adversarial example with $\\varepsilon=1$."
      ],
      "metadata": {
        "id": "WYVd3-MsSMLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your solution here\n",
        "\n"
      ],
      "metadata": {
        "id": "L5qxvfm7Wjm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Alice heard you've attacked her latest model, so she created a new one! Can you break that one too?\n",
        "\n",
        "Alice heard about your adaptive attack on AliceNet, so she's raised the bar with her latest robust model, AliceNetV2. According to her, there's no way to attack this new model!\n",
        "Like last time, Alice won't share with you what her defense is!\n",
        "\n",
        "Your task is to develop an adaptive *targeted* attack. In particular, you must find a way to make small perturbations to the input images such that AliceNetV2 outputs the class \"dog\" every time!\n",
        "\n",
        "###Task Requirements\n",
        "\n",
        "1. **Understand the Defense**: Analyze Alice's model to understand the type of defense implemented. This could involve reviewing the model architecture, preprocessing steps, or any additional mechanisms employed for defense.\n",
        "\n",
        "2. **Design an Adaptive Targeted Attack**: Develop an attack strategy that goes around Alice's defense and makes AliceNetV2 output the calss \"dog\". This might involve modifying standard attack methods like PGD.\n",
        "\n",
        "3. **Generate Adversarial Examples**: Modify all test images from the CIFAR-10 dataset using your adversarial attack. You are allowed to modify the original test images within an $\\ell_\\infty$ ball of radius $8/255$.\n",
        "\n",
        "4. **Test Model Accuracy**: Evaluate how often the AliceNetV2 model predicts the label \"dog\" on these adversarially modified images.\n",
        "\n",
        "\n",
        "###Deliverables\n",
        "\n",
        "* Python code used for your attack and generation of the adversarial CIFAR-10 test set.\n",
        "* A short (up to a few paragraphs) report detailing your analysis of the defense, the approach used for the adaptive attack, and the success rate of your attack on the CIFAR-10 test set.\n"
      ],
      "metadata": {
        "id": "kNj45s0ERR5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "import wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2Y2ZlQGV1VC",
        "outputId": "2b9c1d13-9a97-40bd-9bea-f76b76aa7061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import functools\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "\n",
        "def recursive_getattr(obj, attr, *args):\n",
        "    def _getattr(obj, attr):\n",
        "        return getattr(obj, attr, *args)\n",
        "\n",
        "    return functools.reduce(_getattr, [obj] + attr.split(\".\"))\n",
        "\n",
        "\n",
        "class AliceNetV2_inner(nn.Module):\n",
        "    KERNEL_SIZE = 3\n",
        "    IN_CHANNELS = 3\n",
        "    AVG_POOL_SIZE = 8\n",
        "    LINEAR_MUL = 4 * 4\n",
        "\n",
        "    def __init__(self, num_blocks=2, in_planes=64, num_classes=10, debug=False):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.debug = debug\n",
        "        self.in_planes = in_planes\n",
        "        self.kernel_size = self.KERNEL_SIZE\n",
        "        self.num_blocks = num_blocks\n",
        "\n",
        "        # pre-layer stuff\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            self.IN_CHANNELS,\n",
        "            self.in_planes,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
        "\n",
        "        # make single layer with K BasicBlocks\n",
        "        # BasicBLock: conv1, bn1, conv2, bn2, shortcut\n",
        "        # each conv has `in_planes` filters\n",
        "        get_block = lambda: BasicBlock(self.in_planes, self.in_planes, stride=1)\n",
        "        self.layer = nn.Sequential(*[get_block() for _ in range(num_blocks)])\n",
        "\n",
        "        # register blocks with setattr to make it compatible with masking code\n",
        "        for idx, block in enumerate(self.layer):\n",
        "            setattr(self, f\"block{idx}\", block)\n",
        "\n",
        "        # post-layer stuff\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.avg_pool_2d = nn.AvgPool2d(self.AVG_POOL_SIZE)\n",
        "        self.linear = nn.Linear(self.in_planes * self.LINEAR_MUL, num_classes)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        if self.debug:\n",
        "            print(f\"conv1: {out.shape}\")\n",
        "        out = self.layer(out)\n",
        "        if self.debug:\n",
        "            print(f\"layer: {out.shape}\")\n",
        "        out = self.avg_pool_2d(out)\n",
        "        if self.debug:\n",
        "            print(f\"avg_pool_2d: {out.shape}\")\n",
        "        out = self.flatten(out)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "    def get_components(self, add_weight_suffix=True):\n",
        "        comps = [\"conv1\"]\n",
        "        num_convs = 2\n",
        "        for block_idx in range(self.num_blocks):\n",
        "            for conv_idx in range(1, 1 + num_convs):\n",
        "                comps.append(f\"block{block_idx}.conv{conv_idx}\")\n",
        "\n",
        "        comps.append(\"linear\")\n",
        "\n",
        "        if add_weight_suffix:\n",
        "            return [\"{}.weight\".format(c) for c in comps]\n",
        "        return comps\n",
        "\n",
        "    def get_component_dimensions(self):\n",
        "        comps = self.get_components()\n",
        "        comps_map = {}\n",
        "\n",
        "        for c in comps:\n",
        "            w = recursive_getattr(self, c)\n",
        "            comps_map[c] = w.shape[0]\n",
        "\n",
        "        return comps_map\n",
        "\n",
        "class AliceNetV2(nn.Module):\n",
        "    def __init__(self, num_blocks=2, in_planes=64, num_classes=10):\n",
        "        super(AliceNetV2, self).__init__()\n",
        "        self.model1 = AliceNetV2_inner(num_blocks=num_blocks, in_planes=in_planes, num_classes=num_classes)\n",
        "        self.model2 = AliceNetV2_inner(num_blocks=num_blocks, in_planes=in_planes, num_classes=num_classes)\n",
        "        self.model3 = AliceNetV2_inner(num_blocks=num_blocks, in_planes=in_planes, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for network in [self.model1, self.model2, self.model3]:\n",
        "            out = network(x)\n",
        "            outputs.append(out)\n",
        "        outputs = torch.stack(outputs)\n",
        "        network_predictions = torch.argmax(outputs, dim=-1)\n",
        "        majority_votes = torch.mode(network_predictions, dim=0).values\n",
        "        result = torch.zeros_like(out)\n",
        "        for i, vote in enumerate(majority_votes):\n",
        "            result[i, vote] = 1.\n",
        "        return result\n",
        "\n",
        "\n",
        "def get_alicenet_v2() -> AliceNetV2:\n",
        "\n",
        "    model = AliceNetV2()\n",
        "\n",
        "    url = 'https://www.dropbox.com/scl/fi/awpcptjv4jbrgljn58k0m/alice_model_v2_IOAI.pt?rlkey=1v9hzkkpyqm0xqcyl1dogfwz8&dl=1'\n",
        "    wget.download(url, out='./alicenet_v2.pt', bar=None)\n",
        "    trained_ckpt = torch.load('./alicenet_v2.pt', map_location=\"cpu\")\n",
        "    model.load_state_dict(trained_ckpt)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7ugEPnYK3fSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alicenetv2 = get_alicenet_v2()\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "-2WH8NP7ectD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}